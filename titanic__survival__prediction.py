# -*- coding: utf-8 -*-
"""TITANIC _SURVIVAL _PREDICTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17ULnLU8utS_xe5mYRua4yc0QBIntF3OF
"""

import pandas as pd
df=pd.read_csv("/content/Titanic-Dataset.csv")
df

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Load and Inspect the Data
data = pd.read_csv('/content/Titanic-Dataset.csv')

# Inspect the data
print(data.head())
print(data.info())
print(data.describe(include='all'))

# Step 2: Preprocess the Data
# Drop columns that won't be used or contain too many missing values
data = data.drop(['Name', 'Ticket', 'Cabin'], axis=1)

# Handle missing values
data['Age'].fillna(data['Age'].median(), inplace=True)
data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)

# Convert categorical variables to numeric
categorical_features = ['Sex', 'Embarked']
numeric_features = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']

# Create preprocessing pipelines
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)])

# Separate features and target variable
X = data.drop('Survived', axis=1)
y = data['Survived']

# Preprocess the features
X_preprocessed = preprocessor.fit_transform(X)

# Step 3: Split the Data
X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)

# Step 4: Train the Model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Step 5: Evaluate the Model
y_pred = model.predict(X_test)

print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Optional: Plot feature importances
feature_names = (numeric_features +
                  list(preprocessor.named_transformers_['cat']
                       .named_steps['onehot'].get_feature_names_out()))

feature_importances = model.feature_importances_

# Create a DataFrame for feature importances
features_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})
features_df = features_df.sort_values(by='Importance', ascending=False)

# Plot feature importances
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=features_df)
plt.title('Feature Importances')
plt.show()

# Example new passenger data (for prediction)
new_data = pd.DataFrame({
    'Pclass': [3],
    'Sex': ['female'],
    'Age': [22],
    'SibSp': [1],
    'Parch': [0],
    'Fare': [7.25],
    'Embarked': ['S']
})

# Preprocess the new data
new_data_preprocessed = preprocessor.transform(new_data)

# Predict survival
survival_prediction = model.predict(new_data_preprocessed)
print("Survival Prediction:", "Survived" if survival_prediction[0] == 1 else "Did not survive")