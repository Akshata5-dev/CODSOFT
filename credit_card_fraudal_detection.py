# -*- coding: utf-8 -*-
"""CREDIT_CARD_FRAUDAL_DETECTION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wmw1jJEa1gpBtY7WS1AkOM1XSXauZiz_
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Load the data
data = pd.read_csv('/content/creditcard.csv')

# Check for missing values
missing_values = data.isnull().sum()
print(missing_values)

# Handle missing values (drop rows with missing target variable)
data = data.dropna(subset=['Class'])

# Normalize the data
# Separating features and target variable
X = data.drop(['Amount', 'Class'], axis=1)  # Dropping Amount and Class for normalization
y = data['Class']

# Normalizing the feature columns
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Adding Amount back to the dataset (assuming Amount should not be normalized)
X_scaled = pd.DataFrame(X_scaled, columns=X.columns)
X_scaled['Amount'] = data['Amount']

# Function to evaluate the model
def evaluate_model(y_test, y_pred):
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    cm = confusion_matrix(y_test, y_pred)
    return accuracy, precision, recall, f1, cm

# Using SMOTE for oversampling
smote = SMOTE(random_state=42)
X_resampled_smote, y_resampled_smote = smote.fit_resample(X_scaled, y)

# Split the data into training and testing sets
X_train_smote, X_test_smote, y_train_smote, y_test_smote = train_test_split(X_resampled_smote, y_resampled_smote, test_size=0.2, random_state=42)

# Train Logistic Regression model with SMOTE data
log_reg_smote = LogisticRegression()
log_reg_smote.fit(X_train_smote, y_train_smote)
y_pred_log_reg_smote = log_reg_smote.predict(X_test_smote)

# Train Random Forest model with SMOTE data
rf_clf_smote = RandomForestClassifier(random_state=42)
rf_clf_smote.fit(X_train_smote, y_train_smote)
y_pred_rf_smote = rf_clf_smote.predict(X_test_smote)

# Evaluation metrics for Logistic Regression with SMOTE
log_reg_metrics_smote = evaluate_model(y_test_smote, y_pred_log_reg_smote)
print("Logistic Regression with SMOTE:")
print(f"Accuracy: {log_reg_metrics_smote[0]}")
print(f"Precision: {log_reg_metrics_smote[1]}")
print(f"Recall: {log_reg_metrics_smote[2]}")
print(f"F1 Score: {log_reg_metrics_smote[3]}")
print(f"Confusion Matrix:\n{log_reg_metrics_smote[4]}")

# Evaluation metrics for Random Forest with SMote
rf_metrics_smote = evaluate_model(y_test_smote, y_pred_rf_smote)
print("\nRandom Forest with SMOTE:")
print(f"Accuracy: {rf_metrics_smote[0]}")
print(f"Precision: {rf_metrics_smote[1]}")
print(f"Recall: {rf_metrics_smote[2]}")
print(f"F1 Score: {rf_metrics_smote[3]}")
print(f"Confusion Matrix:\n{rf_metrics_smote[4]}")

# Using Random Undersampling for comparison
rus = RandomUnderSampler(random_state=42)
X_resampled_rus, y_resampled_rus = rus.fit_resample(X_scaled, y)

# Split the data into training and testing sets
X_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_resampled_rus, y_resampled_rus, test_size=0.2, random_state=42)

# Train Logistic Regression model with RUS data
log_reg_rus = LogisticRegression()
log_reg_rus.fit(X_train_rus, y_train_rus)
y_pred_log_reg_rus = log_reg_rus.predict(X_test_rus)

# Train Random Forest model with RUS data
rf_clf_rus = RandomForestClassifier(random_state=42)
rf_clf_rus.fit(X_train_rus, y_train_rus)
y_pred_rf_rus = rf_clf_rus.predict(X_test_rus)

# Evaluation metrics for Logistic Regression with RUS
log_reg_metrics_rus = evaluate_model(y_test_rus, y_pred_log_reg_rus)
print("\nLogistic Regression with RUS:")
print(f"Accuracy: {log_reg_metrics_rus[0]}")
print(f"Precision: {log_reg_metrics_rus[1]}")
print(f"Recall: {log_reg_metrics_rus[2]}")
print(f"F1 Score: {log_reg_metrics_rus[3]}")
print(f"Confusion Matrix:\n{log_reg_metrics_rus[4]}")

# Evaluation metrics for Random Forest with RUS
rf_metrics_rus = evaluate_model(y_test_rus, y_pred_rf_rus)
print("\nRandom Forest with RUS:")
print(f"Accuracy: {rf_metrics_rus[0]}")
print(f"Precision: {rf_metrics_rus[1]}")
print(f"Recall: {rf_metrics_rus[2]}")
print(f"F1 Score: {rf_metrics_rus[3]}")
print(f"Confusion Matrix:\n{rf_metrics_rus[4]}")